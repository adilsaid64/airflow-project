version: '3.9'

x-airflow-common:
  &airflow-common
  build:
    context: .
    dockerfile: Dockerfile
  image: apache/airflow:2.10.1
  env_file:
    - .env
  volumes:
    - ./dags:/opt/airflow/dags
    - ./logs:/opt/airflow/logs
    - ./utils:/opt/airflow/utils
    - ./requirements.txt:/opt/airflow/requirements.txt
  depends_on:
    - postgres
    - redis

services:
  postgres:
    image: postgres:12
    environment:
      POSTGRES_USER: ${POSTGRES_USER}      
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_PORT: ${POSTGRES_PORT}
    ports:
      - "${POSTGRES_PORT}:${POSTGRES_PORT}"
    volumes:
      - ./postgres-data:/var/lib/postgresql/data
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql
    deploy:
      resources:
        limits:
          cpus: '${POSTGRES_CPU_LIMIT}'
          memory: '${POSTGRES_MEMORY_LIMIT}'

  redis:
    image: redis:latest
    ports:
      - "${REDIS_PORT}:${REDIS_PORT}"  
    deploy:
      resources:
        limits:
          cpus: '${REDIS_CPU_LIMIT}'
          memory: '${REDIS_MEMORY_LIMIT}'

  airflow-init:
    <<: *airflow-common
    command: >
      bash -c "pip install -r /opt/airflow/requirements.txt && 
               airflow db init && 
               airflow db upgrade && 
               airflow users create --username ${AIRFLOW_ADMIN_USERNAME} --firstname ${AIRFLOW_ADMIN_FIRSTNAME} --lastname ${AIRFLOW_ADMIN_LASTNAME} --role Admin --email ${AIRFLOW_ADMIN_EMAIL} --password ${AIRFLOW_ADMIN_PASSWORD}"
    restart: "no"
    deploy:
      resources:
        limits:
          cpus: '${AIRFLOW_INIT_CPU_LIMIT}'
          memory: '${AIRFLOW_INIT_MEMORY_LIMIT}'

  airflow-webserver:
    <<: *airflow-common
    command: webserver
    ports:
      - "${AIRFLOW_WEBSERVER_PORT}:${AIRFLOW_WEBSERVER_PORT}"
    depends_on:
      airflow-init:
        condition: service_completed_successfully
    deploy:
      resources:
        limits:
          cpus: '${AIRFLOW_WEBSERVER_CPU_LIMIT}'
          memory: '${AIRFLOW_WEBSERVER_MEMORY_LIMIT}'

  airflow-scheduler:
    <<: *airflow-common
    command: scheduler
    depends_on:
      airflow-init:
        condition: service_completed_successfully
    deploy:
      resources:
        limits:
          cpus: '${AIRFLOW_SCHEDULER_CPU_LIMIT}'
          memory: '${AIRFLOW_SCHEDULER_MEMORY_LIMIT}'

  airflow-worker:
    <<: *airflow-common
    command: celery worker
    depends_on:
      airflow-init:
        condition: service_completed_successfully
    environment:
      - C_FORCE_ROOT=1
    deploy:
      resources:
        limits:
          cpus: '${AIRFLOW_WORKER_CPU_LIMIT}'
          memory: '${AIRFLOW_WORKER_MEMORY_LIMIT}'
      replicas: ${AIRFLOW_WORKER_REPLICAS}

  flower:
    <<: *airflow-common
    command: celery flower --port=${FLOWER_PORT}
    ports:
      - "${FLOWER_PORT}:${FLOWER_PORT}"
    environment:
      - FLOWER_BASIC_AUTH=${FLOWER_USERNAME}:${FLOWER_PASSWORD}
    deploy:
      resources:
        limits:
          cpus: '${FLOWER_CPU_LIMIT}'
          memory: '${FLOWER_MEMORY_LIMIT}'

  minio:
    image: minio/minio:latest
    container_name: minio
    command: server /data --console-address ":${MINIO_CONSOLE_PORT}"
    environment:
      - MINIO_ROOT_USER=${MINIO_ROOT_USER}
      - MINIO_ROOT_PASSWORD=${MINIO_ROOT_PASSWORD}
    volumes:
      - ./minio/data:/data
    ports:
      - "${MINIO_PORT}:${MINIO_PORT}"          
      - "${MINIO_CONSOLE_PORT}:${MINIO_CONSOLE_PORT}"  
    deploy:
      resources:
        limits:
          cpus: '${MINIO_CPU_LIMIT}'
          memory: '${MINIO_MEMORY_LIMIT}'

  metabase:
    image: metabase/metabase:latest
    container_name: metabase
    environment:
      - MB_DB_FILE=/metabase-data/metabase.db
    volumes:
      - ./metabase-data:/metabase-data
    ports:
      - "${METABASE_PORT}:${METABASE_PORT}"
    deploy:
      resources:
        limits:
          cpus: '${METABASE_CPU_LIMIT}'
          memory: '${METABASE_MEMORY_LIMIT}'